{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 100%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "desired_width = 360\n",
    "pd.set_option('display.width', desired_width)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import datetime\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 100%; }\n",
    "</style>\n",
    "\"\"\"))\n",
    "plt.rcParams['figure.figsize'] = [16,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17384, 4229)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDt = pd.read_csv('kc_house_train_data2.csv')\n",
    "testDt = pd.read_csv('kc_house_test_data2.csv')\n",
    "\n",
    "len(trainDt), len(testDt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_features, example_output = (trainDt['sqft_living'], trainDt['price'])  # the [] around 'sqft_living' makes it a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221900.0\n"
     ]
    }
   ],
   "source": [
    "#print (example_features[:]) # this accesses the first row of the data the ':' indicates 'all columns'\n",
    "print (example_output.loc[0]) # and the corresponding output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting output given regression weights\n",
    "\n",
    "Suppose we had the weights [1.0, 1.0] and the features [1.0, 1180.0] and we wanted to compute the predicted output 1.0\\*1.0 + 1.0\\*1180.0 = 1181.0 this is the dot product between these two arrays. If they're numpy arrayws we can use np.dot() to compute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1180.]\n"
     ]
    }
   ],
   "source": [
    "my_weights = np.array([1.]) # the example weights\n",
    "my_features = example_features[0] # we'll use the first data point\n",
    "predicted_value = np.dot(my_features, my_weights)\n",
    "print (predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4, 6],\n",
       "       [2, 4, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2])\n",
    "b = np.array([[1,2,3],[1,2,3]])\n",
    "b*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    if len(weights) > 1:\n",
    "        predictions = np.matmul(feature_matrix, weights)\n",
    "    else:\n",
    "        predictions = weights* feature_matrix       \n",
    "\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180.0\n",
      "2570.0\n"
     ]
    }
   ],
   "source": [
    "##If you want to test your code run the following cell:\n",
    "test_predictions = predict_output(example_features, my_weights)\n",
    "print (test_predictions[0]) # should be 1181.0\n",
    "print (test_predictions[1]) # should be 2571.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Derivative\n",
    "\n",
    "We are now going to move to computing the derivative of the regression cost function. Recall that the cost function is the sum over the data points of the squared difference between an observed output and a predicted output.\n",
    "\n",
    "Since the derivative of a sum is the sum of the derivatives we can compute the derivative for a single data point and then sum over data points. We can write the squared difference between the observed output and predicted output for a single point as follows:\n",
    "\n",
    "(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)^2\n",
    "\n",
    "Where we have k features and a constant. So the derivative with respect to weight w[i] by the chain rule is:\n",
    "\n",
    "2\\*(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)\\* [feature_i]\n",
    "\n",
    "The term inside the paranethesis is just the error (difference between prediction and output). So we can re-write this as:\n",
    "\n",
    "2\\*error\\*[feature_i]\n",
    "\n",
    "That is, the derivative for the weight for feature i is the sum (over data points) of 2 times the product of the error and the feature itself. In the case of the constant then this is just twice the sum of the errors!\n",
    "\n",
    "Recall that twice the sum of the product of two vectors is just twice the dot product of the two vectors. Therefore the derivative for the weight for feature_i is just two times the dot product between the values of feature_i and the current errors. \n",
    "\n",
    "With this in mind complete the following derivative function which computes the derivative of the weight given the value of the feature (over all data points) and the errors (over all data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' and return the value\n",
    "    if np.array(feature).size > 1:\n",
    "        derivative = 2*np.matmul(errors,feature)\n",
    "    else:\n",
    "        derivative = errors * feature\n",
    "\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18752698920.0\n",
      "-18752698920.0\n"
     ]
    }
   ],
   "source": [
    "##To test your feature derivartive run the following:\n",
    "trainDt['constant'] = 1\n",
    "(example_features, example_output) = trainDt[['constant','sqft_living']], trainDt['price'] \n",
    "my_weights = np.array([0., 0.]) # this makes all the predictions 0\n",
    "test_predictions = predict_output(example_features, my_weights) \n",
    "# just like SFrames 2 numpy arrays can be elementwise subtracted with '-': \n",
    "errors = test_predictions - example_output # prediction errors in this case is just the -example_output\n",
    "feature = example_features.iloc[:,0] # let's compute the derivative with respect to 'constant', the \":\" indicates \"all rows\"\n",
    "derivative = feature_derivative(errors, feature)\n",
    "print (derivative)\n",
    "print (-np.sum(example_output)*2) # should be the same as derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "Now we will write a function that performs a gradient descent. The basic premise is simple. Given a starting point we update the current weights by moving in the negative gradient direction. Recall that the gradient is the direction of *increase* and therefore the negative gradient is the direction of *decrease* and we're trying to *minimize* a cost function. \n",
    "\n",
    "The amount by which we move in the negative gradient *direction*  is called the 'step size'. We stop when we are 'sufficiently close' to the optimum. We define this by requiring that the magnitude (length) of the gradient vector to be smaller than a fixed 'tolerance'.\n",
    "\n",
    "With this in mind, complete the following gradient descent function below using your derivative function above. For each step in the gradient descent we update the weight for each feature befofe computing our stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt # recall that the magnitude/length of a vector [g[0], g[1], g[2]] is sqrt(g[0]^2 + g[1]^2 + g[2]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    gradient_lst = []\n",
    "    ctr = 0\n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    while (not converged):\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        prediction = predict_output(feature_matrix, weights)\n",
    "\n",
    "        # compute the errors as predictions - output\n",
    "        error = prediction - output\n",
    "\n",
    "        gradient_sum_squares = 0 # initialize the gradient sum of squares\n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        for i in range(0,len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative = feature_derivative(error, feature_matrix)\n",
    "            #print(\"***\", derivative)\n",
    "            # add the squared value of the derivative to the gradient sum of squares (for assessing convergence)\n",
    "            gradient_sum_squares += derivative[i] * derivative[i]\n",
    "\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "            weights[i] = weights[i] - step_size*derivative[i]\n",
    "            \n",
    "        # compute the square-root of the gradient sum of squares to get the gradient magnitude:\n",
    "        #print (gradient_sum_squares)\n",
    "        gradient_magnitude = sqrt(gradient_sum_squares)\n",
    "        ctr +=1\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "        gradient_lst.append(gradient_magnitude)\n",
    "        if ctr >3:\n",
    "            print (np.gradient(gradient_lst)[ctr-1])\n",
    "            if abs(np.gradient(gradient_lst)[ctr-1]) < 0.05:\n",
    "                converged = True\n",
    "    print (weights, ctr)\n",
    "    plt.rcParams['figure.figsize'] = [8,4]\n",
    "    plt.plot(gradient_lst)\n",
    "    plt.semilogy()\n",
    "    return(weights, gradient_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note before we run the gradient descent. Since the gradient is a sum over all the data points and involves a product of an error and a feature the gradient itself will be very large since the features are large (squarefeet) and the output is large (prices). So while you might expect \"tolerance\" to be small, small is only relative to the size of the features. \n",
    "\n",
    "For similar reasons the step size will be much smaller than you might expect but this is because the gradient has such large values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Gradient Descent as Simple Regression\n",
    "\n",
    "First let's split the data into training and test data.\n",
    "Although the gradient descent is designed for multiple regression since the constant is now a feature we can use the gradient descent function to estimat the parameters in the simple regression on squarefeet. The folowing cell sets up the feature_matrix, output, initial weights and step size for the first model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test out the gradient descent\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7\n",
    "(feature_matrix1, output) = trainDt[['constant','sqft_living']], trainDt['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2523732502956.0117\n",
      "-655374314517.1423\n",
      "-170190577495.73688\n",
      "-44195861846.81816\n",
      "-11476982022.99819\n",
      "-2980394653.961095\n",
      "-773961856.4297742\n",
      "-200983777.10986066\n",
      "-52184097.57568956\n",
      "[-46999.88716555    281.91211918] 12\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Next run your gradient descent with the above parameters.\n",
    "\n",
    "weights1, grad_lst = regression_gradient_descent(feature_matrix1, output, initial_weights, step_size, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.74240798e+13, -2.35712674e+13, -6.12109372e+12, -1.58955341e+12,\n",
       "       -4.12782446e+11, -1.07193220e+11, -2.78364219e+10, -7.22868834e+09,\n",
       "       -1.87717826e+09, -4.87472817e+08, -1.26583937e+08, -5.21840976e+07])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.gradient(grad_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do your weights compare to those achieved in week 1 (don't expect them to be exactly the same)? \n",
    "\n",
    "**Quiz Question: What is the value of the weight for sqft_living -- the second element of ‘simple_weights’ (rounded to 1 decimal place)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your newly estimated weights and your predict_output() function to compute the predictions on all the TEST data (you will need to create a numpy array of the test feature_matrix and test output first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDt['constant'] = 1\n",
    "(feature_matrixtest1, outputtest) = testDt[['constant','sqft_living']], testDt['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Now compute your predictions using test_simple_feature_matrix and your weights from above.\n",
    "predict_y = predict_output(feature_matrixtest1, weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38793290.36852571"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = outputtest - predict_y\n",
    "RSS = sqrt(np.matmul(predict_y,predict_y))\n",
    "RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 1 (round to nearest dollar)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356134.0, 310000.0)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(predict_y[0]), outputtest[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Results with sklearn LinearRegression library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(trainDt[['constant','sqft_living']], trainDt['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        , 281.95883963])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([356085.0615985 , 784662.49783662, 435033.53669499, ...,\n",
       "       663420.19679557, 604208.8404732 , 240481.93735006])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.predict(testDt[['constant','sqft_living']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a multiple regression\n",
    "\n",
    "Now we will use more than one actual feature. Use the following code to produce the weights for a second model with the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "(feature_matrix2, output) = trainDt[['constant','sqft_living', 'sqft_living15']], trainDt['price']\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4785112186902.83\n",
      "-1346698285951.474\n",
      "-272676678773.3495\n",
      "-45692073199.41162\n",
      "-17536586643.05481\n",
      "-14372845334.45935\n",
      "-13760244120.389038\n",
      "-13406994890.498901\n",
      "-13086258693.801758\n",
      "-12775510315.622803\n",
      "-12472369159.577942\n",
      "-12176443508.897278\n",
      "-11887541352.956238\n",
      "-11605493999.361694\n",
      "-11330138606.952637\n",
      "-11061316380.365784\n",
      "-10798872309.807007\n",
      "-10542655065.065186\n",
      "-10292516906.60608\n",
      "-10048313600.223877\n",
      "-9809904333.862122\n",
      "-9577151636.404602\n",
      "-9349921298.428162\n",
      "-9128082294.789795\n",
      "-8911506709.09613\n",
      "-8700069659.931763\n",
      "-8493649228.855957\n",
      "-8292126390.103088\n",
      "-8095384941.94397\n",
      "-7903311439.689941\n",
      "-7715795130.272888\n",
      "-7532727888.384399\n",
      "-7354004154.130066\n",
      "-7179520872.159668\n",
      "-7009177432.248718\n",
      "-6842875611.27356\n",
      "-6680519516.587585\n",
      "-6522015530.720032\n",
      "-6367272257.394165\n",
      "-6216200468.830841\n",
      "-6068713054.293793\n",
      "-5924724969.863312\n",
      "-5784153189.395172\n",
      "-5646916656.649963\n",
      "-5512936238.551331\n",
      "-5382134679.559174\n",
      "-5254436557.118988\n",
      "-5129768238.175354\n",
      "-5008057836.71405\n",
      "-4889235172.306549\n",
      "-4773231729.649261\n",
      "-4659980619.051392\n",
      "-4549416537.864838\n",
      "-4441475732.835907\n",
      "-4336095963.335266\n",
      "-4233216465.475586\n",
      "-4132777917.072174\n",
      "-4034722403.432556\n",
      "-3938993383.969391\n",
      "-3845535659.591156\n",
      "-3754295340.8799133\n",
      "-3665219817.009033\n",
      "-3578257725.413971\n",
      "-3493358922.1784363\n",
      "-3410474453.106964\n",
      "-3329556525.512497\n",
      "-3250558480.648941\n",
      "-3173434766.808487\n",
      "-3098140913.0589905\n",
      "-3024633503.5976257\n",
      "-2952870152.716797\n",
      "-2882809480.3676605\n",
      "-2814411088.2916565\n",
      "-2747635536.737335\n",
      "-2682444321.709137\n",
      "-2618799852.7663727\n",
      "-2556665431.3572235\n",
      "-2496005229.6428986\n",
      "-2436784269.852524\n",
      "-2378968404.102661\n",
      "-2322524294.7194977\n",
      "-2267419395.001648\n",
      "-2213621930.4660645\n",
      "-2161100880.5162506\n",
      "-2109825960.5633087\n",
      "-2059767604.5557709\n",
      "-2010896947.9382477\n",
      "-1963185811.0025787\n",
      "-1916606682.6414185\n",
      "-1871132704.4836884\n",
      "-1826737655.4067535\n",
      "-1783395936.423584\n",
      "-1741082555.9060059\n",
      "-1699773115.1965942\n",
      "-1659443794.5186615\n",
      "-1620071339.2556381\n",
      "-1581633046.5333939\n",
      "-1544106752.1359406\n",
      "-1507470817.7199936\n",
      "-1471704118.341217\n",
      "-1436786030.2716064\n",
      "-1402696419.107521\n",
      "-1369415628.1608047\n",
      "-1336924467.121811\n",
      "-1305204200.9986725\n",
      "-1274236539.3106537\n",
      "-1244003625.5394135\n",
      "-1214488026.84124\n",
      "-1185672723.984848\n",
      "-1157541101.542076\n",
      "-1130076938.310814\n",
      "-1103264397.9555435\n",
      "-1077088019.8778076\n",
      "-1051532710.3043365\n",
      "-1026583733.578804\n",
      "-1002226703.6678467\n",
      "-978447575.8675613\n",
      "-955232638.6997604\n",
      "-932568506.0109177\n",
      "-910442109.250618\n",
      "-888840689.9373169\n",
      "-867751792.2990112\n",
      "-847163256.0954208\n",
      "-827063209.603447\n",
      "-807440062.771389\n",
      "-788282500.5359192\n",
      "-769579476.2989883\n",
      "-751320205.5574188\n",
      "-733494159.684597\n",
      "-716091059.8575478\n",
      "-699100871.1361198\n",
      "-682513796.6644516\n",
      "-666320272.0392303\n",
      "-650510959.7759666\n",
      "-635076743.9419937\n",
      "-620008724.884716\n",
      "-605298214.1139259\n",
      "-590936729.2792168\n",
      "-576915989.2912674\n",
      "-563227909.5336914\n",
      "-549864597.2123032\n",
      "-536818346.80010986\n",
      "-524081635.5888405\n",
      "-511647119.3632088\n",
      "-499507628.1539917\n",
      "-487656162.1098175\n",
      "-476085887.4605675\n",
      "-464790132.5757942\n",
      "-453762384.11899185\n",
      "-442996283.2888336\n",
      "-432485622.1574974\n",
      "-422224340.0859108\n",
      "-412206520.2325001\n",
      "-402426386.1424465\n",
      "-392878298.4110298\n",
      "-383556751.43634605\n",
      "-374456370.2492008\n",
      "-365571907.4007473\n",
      "-356898239.9501934\n",
      "-348430366.50395584\n",
      "-340163404.3307991\n",
      "-332092586.5515156\n",
      "-324213259.3854008\n",
      "-316520879.4709053\n",
      "-309011011.2399502\n",
      "-301679324.36771965\n",
      "-294521591.2697773\n",
      "-287533684.66716766\n",
      "-280711575.20716476\n",
      "-274051329.13601303\n",
      "-267549106.03691483\n",
      "-261201156.60752678\n",
      "-255003820.50803375\n",
      "-248953524.2388115\n",
      "-243046779.09108734\n",
      "-237280179.12866402\n",
      "-231650399.2238617\n",
      "-226154193.14351463\n",
      "-220788391.6774063\n",
      "-215549900.80525398\n",
      "-210435699.9185772\n",
      "-205442840.0757723\n",
      "-200568442.30402374\n",
      "-195809695.93769836\n",
      "-191163856.99540997\n",
      "-186628246.60309315\n",
      "-182200249.44544506\n",
      "-177877312.25878143\n",
      "-173656942.36024284\n",
      "-169536706.20588398\n",
      "-165514227.99380493\n",
      "-161587188.2905426\n",
      "-157753322.69242287\n",
      "-154010420.52395344\n",
      "-150356323.5606289\n",
      "-146788924.78100395\n",
      "-143306167.16125488\n",
      "-139906042.4773531\n",
      "-136586590.15830803\n",
      "-133345896.14620018\n",
      "-130182091.7983818\n",
      "-127093352.80827522\n",
      "-124077898.1502037\n",
      "-121133989.06281948\n",
      "-118259928.03192806\n",
      "-115454057.82075691\n",
      "-112714760.51674652\n",
      "-110040456.58824253\n",
      "-107429603.9854641\n",
      "-104880697.2424345\n",
      "-102392266.61299658\n",
      "-99962877.22235298\n",
      "-97591128.24232054\n",
      "-95275652.07780743\n",
      "-93015113.58382225\n",
      "-90808209.2924962\n",
      "-88653666.66340733\n",
      "-86550243.3471632\n",
      "-84496726.47344112\n",
      "-82491931.94450235\n",
      "-80534703.76222897\n",
      "-78623913.35070133\n",
      "-76758458.91616583\n",
      "-74937264.80108881\n",
      "-73159280.87414646\n",
      "-71423481.91562366\n",
      "-69728867.03412151\n",
      "-68074459.08232212\n",
      "-66459304.100011826\n",
      "-64882470.75881338\n",
      "-63343049.826975346\n",
      "-61840153.64903307\n",
      "-60372915.62436485\n",
      "-58940489.72033596\n",
      "-57542049.97161293\n",
      "-56176790.01415014\n",
      "-54843922.612514496\n",
      "-53542679.213180065\n",
      "-52272309.4945631\n",
      "-51032080.93719721\n",
      "-49821278.40535617\n",
      "-48639203.726964\n",
      "-47485175.295226574\n",
      "-46358527.678417444\n",
      "-45258611.22925472\n",
      "-44184791.71856928\n",
      "-43136449.95974517\n",
      "-42112981.4608953\n",
      "-41113796.07205629\n",
      "-40138317.64307952\n",
      "-39185983.69828844\n",
      "-38256245.101517916\n",
      "-37348565.75208473\n",
      "-36462422.2610507\n",
      "-35597303.66693425\n",
      "-34752711.12305641\n",
      "-33928157.623357296\n",
      "-33123167.714674234\n",
      "-32337277.226670742\n",
      "-31570032.999653816\n",
      "-30820992.626740456\n",
      "-30089724.19650054\n",
      "-29375806.0487597\n",
      "-28678826.523047686\n",
      "-27998383.730534554\n",
      "-27334085.312640667\n",
      "-26685548.226189375\n",
      "-26052398.509644985\n",
      "-25434271.08122313\n",
      "-24830809.51238191\n",
      "-24241665.840335727\n",
      "[-9.99999688e+04  2.45072603e+02  6.52795267e+01] 274\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Use the above parameters to estimate the model weights. Record these values for your quiz.\n",
    "initial_weights = [-100000., 1., 1.]\n",
    "weights2, grad_lst = regression_gradient_descent(feature_matrix2, output, initial_weights, step_size, tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your newly estimated weights and the predict_output function to compute the predictions on the TEST data. Don't forget to create a numpy array for these features from the test set first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrixtest2, outputtest = testDt[['constant','sqft_living', 'sqft_living15']], testDt['price']\n",
    "predict_y = predict_output(feature_matrixtest2, weights2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 2 (round to nearest dollar)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366651.41162949393, 310000.0)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y[0], outputtest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38860826.617531"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = outputtest - predict_y\n",
    "RSS = sqrt(np.matmul(predict_y,predict_y))\n",
    "RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
