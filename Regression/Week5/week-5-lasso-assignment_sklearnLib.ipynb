{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int,\n",
    "              'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, \n",
    "              'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int,\n",
    "              'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales = pd.read_csv('kc_house_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float, before creating a new feature.\n",
    "sales['floors'] = sales['floors'].astype(float) \n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.Series(['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the entire house dataset, learn regression weights using an L1 penalty of 5e2. Make sure to add \"normalize=True\" when creating the Lasso object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=500.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all =  linear_model.Lasso(alpha= 5e2, normalize= True)\n",
    "model_all.fit(sales[all_features], sales['price']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.        ,     0.        ,     0.        ,   134.43931396,\n",
       "           0.        ,     0.        ,     0.        ,     0.        ,\n",
       "           0.        ,     0.        , 24750.00458561,     0.        ,\n",
       "       61749.10309071,     0.        ,     0.        ,    -0.        ,\n",
       "           0.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.coef_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series(model_all.coef_ !=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     sqft_living\n",
       "10           view\n",
       "12          grade\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Lasso' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-fa59897158e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coefficients'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Lasso' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model_all['coefficients'].print_rows(num_rows=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "a[a<3]\n",
    "c= [1,2,3]\n",
    "c[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets. Download the provided csv files containing training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('wk3_kc_house_test_data.csv', dtype=dtype_dict)\n",
    "training = pd.read_csv('wk3_kc_house_train_data.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('wk3_kc_house_valid_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the 4 features as in #1:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['sqft_living_sqrt'] = testing['sqft_living'].apply(sqrt)\n",
    "testing['sqft_lot_sqrt'] = testing['sqft_lot'].apply(sqrt)\n",
    "testing['bedrooms_square'] = testing['bedrooms']*testing['bedrooms']\n",
    "testing['floors_square'] = testing['floors']*testing['floors']\n",
    "\n",
    "training['sqft_living_sqrt'] = training['sqft_living'].apply(sqrt)\n",
    "training['sqft_lot_sqrt'] = training['sqft_lot'].apply(sqrt)\n",
    "training['bedrooms_square'] = training['bedrooms']*training['bedrooms']\n",
    "training['floors_square'] = training['floors']*training['floors']\n",
    "\n",
    "validation['sqft_living_sqrt'] = validation['sqft_living'].apply(sqrt)\n",
    "validation['sqft_lot_sqrt'] = validation['sqft_lot'].apply(sqrt)\n",
    "validation['bedrooms_square'] = validation['bedrooms']*validation['bedrooms']\n",
    "validation['floors_square'] = validation['floors']*validation['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l1_penalties = np.logspace(-1,7,num=13)\n",
    "#training[all_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manje_000\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "RSS_array = []\n",
    "for l1_penalty in l1_penalties:\n",
    "    #print(l1_penalty)\n",
    "    model = linear_model.Lasso(alpha= l1_penalty, normalize= True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    RSS = sum((validation['price'] - model.predict(validation[all_features]))**2)\n",
    "    RSS_array.append(RSS)\n",
    "    #print(\"***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " 10.0,\n",
       " array([1.00000000e-01, 4.64158883e-01, 2.15443469e+00, 1.00000000e+01,\n",
       "        4.64158883e+01, 2.15443469e+02, 1.00000000e+03, 4.64158883e+03,\n",
       "        2.15443469e+04, 1.00000000e+05, 4.64158883e+05, 2.15443469e+06,\n",
       "        1.00000000e+07]),\n",
       " [403459589991008.75,\n",
       "  403192245817239.25,\n",
       "  402066410602806.25,\n",
       "  398213327300133.9,\n",
       "  410208658629800.2,\n",
       "  447352172543769.8,\n",
       "  645898733633801.6,\n",
       "  1222506859427156.8,\n",
       "  1222506859427156.8,\n",
       "  1222506859427156.8,\n",
       "  1222506859427156.8,\n",
       "  1222506859427156.8,\n",
       "  1222506859427156.8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(RSS_array), l1_penalties[np.argmin(RSS_array)], l1_penalties,  RSS_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manje_000\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\matplotlib\\axes\\_base.py:3449: UserWarning: Attempted to set non-positive ylimits for log-scale axis; invalid limits will be ignored.\n",
      "  'Attempted to set non-positive ylimits for log-scale axis; '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(398213327300133.9, 500000000000000.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(RSS_array)\n",
    "plt.semilogy()\n",
    "plt.ylim(0,5e14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION. *** What was the best value for the `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.61445628e+04,  3.73245384e+02,  5.08412433e+04,  6.17853560e+02,\n",
       "       -4.44113549e+04,  7.85623065e-01, -7.01194765e+02, -0.00000000e+00,\n",
       "        5.01420046e+03,  6.19488752e+05,  3.80418557e+04,  2.49987718e+04,\n",
       "        1.28716235e+05,  0.00000000e+00,  0.00000000e+00, -3.29383118e+03,\n",
       "        1.00573209e+01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.Lasso(alpha= 10, normalize= True)\n",
    "model.fit(training[all_features], training['price'])\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6630155.668628368)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(model.intercept_), model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(model.coef_) + np.count_nonzero(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`.\n",
    "\n",
    "Assign 7 to the variable ‘max_nonzeros’.\n",
    "\n",
    "Exploring large range of l1_penalty\n",
    "\n",
    "For l1_penalty in np.logspace(1, 4, num=20):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   10.        ,    14.38449888,    20.69138081,    29.76351442,\n",
       "          42.81332399,    61.58482111,    88.58667904,   127.42749857,\n",
       "         183.29807108,   263.66508987,   379.26901907,   545.55947812,\n",
       "         784.75997035,  1128.83789168,  1623.77673919,  2335.72146909,\n",
       "        3359.81828628,  4832.93023857,  6951.92796178, 10000.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_penalty_values = np.logspace(1, 4, num=20)\n",
    "l1_penalty_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "Fit a regression model with a given l1_penalty on TRAIN data. Add \"alpha=l1_penalty\" and \"normalize=True\" to the parameter list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 14, 14, 14, 12, 11, 10, 9, 6, 5, 5, 5, 4, 2, 2, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "nzlist = []\n",
    "for l1_penalty in l1_penalty_values:\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize= True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    #print(model.coef_)\n",
    "    nzlist.append(np.count_nonzero(model.coef_))\n",
    "print(nzlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzeros` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzeros` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 15, 15, 15, 13, 12, 11, 10, 7, 6, 6, 6, 5, 3, 3, 2, 1, 1, 1, 1]\n",
      "2.1052631578947367 2.4210526315789473\n",
      "[10, 10, 9, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6]\n",
      "2.1717451523545703 2.3213296398891967\n",
      "[8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6]\n",
      "2.1796180201195505 2.3213296398891967\n",
      "[8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6]\n",
      "2.1796180201195505 2.3213296398891967\n",
      "Minimum L2Penalty:  153.8426\n",
      "Maximum L2Penalty:  206.0019\n"
     ]
    }
   ],
   "source": [
    "from math import log10, pow\n",
    "minv = 1\n",
    "maxv = 4\n",
    "nzlist= []\n",
    "l1_penalty_values = np.logspace(minv, maxv, num=20)\n",
    "minl1P = l1_penalty_values[0]\n",
    "maxl2P = l1_penalty_values[19]\n",
    "zsum = 0\n",
    "while zsum <18:\n",
    "    nzlist = []\n",
    "    for l1_penalty in l1_penalty_values:\n",
    "        #print(log10(l1_penalty))\n",
    "        model = linear_model.Lasso(alpha=l1_penalty, normalize= True)\n",
    "        model.fit(training[all_features], training['price'])\n",
    "        #print(model.intercept_)\n",
    "        #print(type(model.coef_))\n",
    "        nzlist.append(np.count_nonzero(np.append(model.coef_,model.intercept_)))\n",
    "    print(nzlist)\n",
    "    nzlist = np.array(nzlist)\n",
    "    minv = log10(l1_penalty_values[sum(nzlist >7) -1])\n",
    "    maxv = log10(l1_penalty_values[20 - sum(nzlist <7)]) \n",
    "    print (minv, maxv)\n",
    "    l1_penalty_values = np.logspace(minv, maxv, num=20)\n",
    "    zsum = sum(nzlist == 7)\n",
    "#nzli\n",
    "print (\"Minimum L2Penalty: \", round(l1_penalty_values[1],4))\n",
    "print (\"Maximum L2Penalty: \", round(l1_penalty_values[18],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3138711335855313 2.3213296398891967\n",
      "209.57025406233632\n",
      "[7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n"
     ]
    }
   ],
   "source": [
    "minv = log10(l1_penalty_values[18])\n",
    "maxv = log10(l1_penalty_values[19]) \n",
    "print (minv, maxv)\n",
    "l1_penaltys = np.logspace(minv, maxv, num=20)\n",
    "print(l1_penalty)\n",
    "nzlist = []\n",
    "for l1_penalty in l1_penaltys:\n",
    "    #print(log10(l1_penalty))\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize= True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    #print(model.intercept_)\n",
    "    #print(type(model.coef_))\n",
    "    nzlist.append(np.count_nonzero(np.append(model.coef_,model.intercept_)))\n",
    "print(nzlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nzlist[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_penalty_min = minv\n",
    "l1_penalty_max = maxv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION.*** What values did you find for `l1_penalty_min` and `l1_penalty_max`, respectively? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151.22305943 153.84257003 156.50745622 159.218504   161.97651301\n",
      " 164.78229669 167.63668262 170.54051269 173.49464338 176.499946\n",
      " 179.55730697 182.66762805 185.83182661 189.05083595 192.32560549\n",
      " 195.65710112 199.04630547 202.49421817 206.00185617 209.57025406]\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x248991c7f28>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RSS_lst = []\n",
    "l1_penalties = np.logspace(minv, maxv,20)\n",
    "print(l1_penalties)\n",
    "for l1_penalty in l1_penalties[1:20]:\n",
    "    #print(l1_penalty)\n",
    "    model = linear_model.Lasso(alpha=l1_penalty, normalize= True)\n",
    "    model.fit(training[all_features], training['price'])\n",
    "    RSS = sum((validation['price'] - model.predict(validation[all_features]))**2)\n",
    "    RSS_lst.append(RSS)\n",
    "    print(np.count_nonzero(model.coef_))\n",
    "plt.plot(RSS_lst)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_coefficients(model):    \n",
    "    # Get the degree of the polynomial\n",
    "    deg = len(model.coef_)\n",
    "\n",
    "    # Get learned parameters as a list\n",
    "    w = list(model.coef_)\n",
    "\n",
    "    # Numpy has a nifty function to print out polynomials in a pretty way\n",
    "    # (We'll use it, but it needs the parameters in the reverse order)\n",
    "    print ('Learned polynomial for degree ' + str(deg) + ':')\n",
    "    w.reverse()\n",
    "    print (np.poly1d(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_Panelty corresponding minimum RSS on VAlidation Data(for 7 features):  153.84257002616587\n",
      "Following features have non-zero coefficient: \n",
      "2       bathrooms\n",
      "3     sqft_living\n",
      "9      waterfront\n",
      "10           view\n",
      "12          grade\n",
      "15       yr_built\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "l1_penalty_final = l1_penalties[1+np.argmin(RSS_lst)]\n",
    "print('l1_Panelty corresponding minimum RSS on VAlidation Data(for 7 features): ', l1_penalty_final )\n",
    "#print (\" Corresponding Generated Model: \")\n",
    "model = linear_model.Lasso(alpha=l1_penalty_final, normalize= True)\n",
    "model.fit(training[all_features], training['price'])\n",
    "#print_coefficients(model)\n",
    "\n",
    "a = pd.Series(model.coef_ !=0)\n",
    "print (\"Following features have non-zero coefficient: \")\n",
    "print(all_features[a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
